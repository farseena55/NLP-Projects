{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMlEF+sJlbiW7e6YMR9v9w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7bQg9vZk4KOc","executionInfo":{"status":"ok","timestamp":1717146144857,"user_tz":-240,"elapsed":2573,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}}},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["help(nltk) #shows details of nltk library"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qm-vkSy_4qdn","executionInfo":{"status":"ok","timestamp":1717146157363,"user_tz":-240,"elapsed":10,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"859cbd10-1e56-4b3f-96c6-c6fe42be5573"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package nltk:\n","\n","NAME\n","    nltk\n","\n","DESCRIPTION\n","    The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing.  A free online book is available.\n","    (If you use the library for academic research, please cite the book.)\n","    \n","    Steven Bird, Ewan Klein, and Edward Loper (2009).\n","    Natural Language Processing with Python.  O'Reilly Media Inc.\n","    https://www.nltk.org/book/\n","    \n","    isort:skip_file\n","    \n","    @version: 3.8.1\n","\n","PACKAGE CONTENTS\n","    app (package)\n","    book\n","    ccg (package)\n","    chat (package)\n","    chunk (package)\n","    classify (package)\n","    cli\n","    cluster (package)\n","    collections\n","    collocations\n","    compat\n","    corpus (package)\n","    data\n","    decorators\n","    downloader\n","    draw (package)\n","    featstruct\n","    grammar\n","    help\n","    inference (package)\n","    internals\n","    jsontags\n","    langnames\n","    lazyimport\n","    lm (package)\n","    metrics (package)\n","    misc (package)\n","    parse (package)\n","    probability\n","    sem (package)\n","    sentiment (package)\n","    stem (package)\n","    tag (package)\n","    tbl (package)\n","    test (package)\n","    text\n","    tgrep\n","    tokenize (package)\n","    toolbox\n","    translate (package)\n","    tree (package)\n","    treeprettyprinter\n","    treetransforms\n","    twitter (package)\n","    util\n","    wsd\n","\n","SUBMODULES\n","    agreement\n","    aline\n","    api\n","    arlstem\n","    arlstem2\n","    association\n","    bleu_score\n","    bllip\n","    boxer\n","    brill\n","    brill_trainer\n","    casual\n","    chart\n","    chrf_score\n","    cistem\n","    confusionmatrix\n","    corenlp\n","    crf\n","    decisiontree\n","    dependencygraph\n","    destructive\n","    discourse\n","    distance\n","    drt\n","    earleychart\n","    evaluate\n","    featurechart\n","    gale_church\n","    gdfa\n","    gleu_score\n","    glue\n","    hmm\n","    hunpos\n","    ibm1\n","    ibm2\n","    ibm3\n","    ibm4\n","    ibm5\n","    ibm_model\n","    isri\n","    lancaster\n","    legality_principle\n","    lfg\n","    linearlogic\n","    logic\n","    mace\n","    malt\n","    mapping\n","    maxent\n","    megam\n","    meteor_score\n","    mwe\n","    naivebayes\n","    nist_score\n","    nonprojectivedependencyparser\n","    paice\n","    pchart\n","    perceptron\n","    phrase_based\n","    porter\n","    positivenaivebayes\n","    projectivedependencyparser\n","    prover9\n","    punkt\n","    recursivedescent\n","    regexp\n","    relextract\n","    repp\n","    resolution\n","    ribes_score\n","    rslp\n","    rte_classify\n","    scikitlearn\n","    scores\n","    segmentation\n","    senna\n","    sequential\n","    sexpr\n","    shiftreduce\n","    simple\n","    snowball\n","    sonority_sequencing\n","    spearman\n","    stack_decoder\n","    stanford\n","    stanford_segmenter\n","    tableau\n","    tadm\n","    textcat\n","    texttiling\n","    tnt\n","    toktok\n","    transitionparser\n","    treebank\n","    viterbi\n","    weka\n","    wordnet\n","\n","FUNCTIONS\n","    demo()\n","        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n","    \n","    tee(iterable, n=2, /)\n","        Returns a tuple of n independent iterators.\n","\n","DATA\n","    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n","    SLASH = *slash*\n","    TYPE = *type*\n","    __author_email__ = 'nltk.team@gmail.com'\n","    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n","    __copyright__ = 'Copyright (C) 2001-2023 NLTK Project.\\n\\nDistribut......\n","    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n","    __license__ = 'Apache License, Version 2.0'\n","    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...NL...\n","    __maintainer__ = 'NLTK Team'\n","    __maintainer_email__ = 'nltk.team@gmail.com'\n","    __url__ = 'https://www.nltk.org/'\n","    app = <LazyModule 'nltk.app'>\n","    chat = <LazyModule 'nltk.chat'>\n","    corpus = <LazyModule 'nltk.corpus'>\n","    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n","    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n","    toolbox = <LazyModule 'nltk.toolbox'>\n","    version_file = '/usr/local/lib/python3.10/dist-packages/nltk/VERSION'\n","\n","VERSION\n","    3.8.1\n","\n","AUTHOR\n","    NLTK Team\n","\n","FILE\n","    /usr/local/lib/python3.10/dist-packages/nltk/__init__.py\n","\n","\n"]}]},{"cell_type":"code","source":["from nltk.corpus import stopwords"],"metadata":{"id":"Mj0AHN4B4vvz","executionInfo":{"status":"ok","timestamp":1717146348893,"user_tz":-240,"elapsed":376,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","stopwordss = stopwords.words('english')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uLmPirK5U_B","executionInfo":{"status":"ok","timestamp":1717146503244,"user_tz":-240,"elapsed":360,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"800d26f7-29c6-4f56-8d7e-f948e756fad7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["stopwordss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIU5DaPC5nZh","executionInfo":{"status":"ok","timestamp":1717146526956,"user_tz":-240,"elapsed":359,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"9b91aeec-a557-433d-f92d-cf1390abdb00"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["nltk.download('punkt') # packge for tokenization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCYU6O_47C4Q","executionInfo":{"status":"ok","timestamp":1717146780225,"user_tz":-240,"elapsed":587,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"0ab5f4e8-b465-45f8-d0fe-d4995d610a85"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["sentence = \"at eight o clock on thursday morning,hello how are you\"\n","\n","tokens = nltk.word_tokenize(sentence)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFWDVDAO6J_N","executionInfo":{"status":"ok","timestamp":1717146781432,"user_tz":-240,"elapsed":9,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"eca936a3-6dd4-4adf-e0e4-8d8ee5089659"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['at',\n"," 'eight',\n"," 'o',\n"," 'clock',\n"," 'on',\n"," 'thursday',\n"," 'morning',\n"," ',',\n"," 'hello',\n"," 'how',\n"," 'are',\n"," 'you']"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentence = '\"at eight o clock on thursday morning,hello how are you\"'\n","\n","stopwordss = set(stopwords.words('english'))\n","\n","\n","tokens = word_tokenize(sentence)\n","tokens\n","\n","\n","words = [w for w in tokens if not w in stopwordss]\n","\n","words\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xZQ2QoY62Ni","executionInfo":{"status":"ok","timestamp":1717147329388,"user_tz":-240,"elapsed":381,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"26d3af8b-a300-49a1-a74e-45f1de720f6c"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['``', 'eight', 'clock', 'thursday', 'morning', ',', 'hello', \"''\"]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","sentence = '\"at Eight o Clock on Thursday Morning,hello how are you\"'\n","\n","stopwordss = set(stopwords.words('english'))\n","\n","\n","tokens = word_tokenize(sentence)\n","tokens\n","\n","\n","words = [w.lower() for w in tokens if not w in stopwordss]\n","\n","words\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxw7QV1r8wda","executionInfo":{"status":"ok","timestamp":1717147448284,"user_tz":-240,"elapsed":10,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"8972424e-fe91-4e76-db4d-02b8783759b4"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['``', 'eight', 'clock', 'thursday', 'morning', ',', 'hello', \"''\"]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"uaEeJEDQ9q3c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["this is not good\n","this, is, not, good\n","\n","ngrams\n","\n","ngram = 1\n","this\n","is\n","not\n","good\n","\n","ngram = 2\n","this is\n","is not\n","not good\n","\n","ngam = 3\n","this is not\n","is not good"],"metadata":{"id":"ZQxF2kEa-AhD"}},{"cell_type":"code","source":["from nltk.util import ngrams\n","\n","sentence = '\"at Eignt o Clock on thursday,hello how are you'\n","Ngrams = ngrams(sequence=nltk.word_tokenize(sentence), n=3)\n","for grms in Ngrams:\n","    print(grms)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtOwL-6r_N3O","executionInfo":{"status":"ok","timestamp":1717147981666,"user_tz":-240,"elapsed":10,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"b6a5295a-49d4-4aea-a013-3434de54b506"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["('``', 'at', 'Eignt')\n","('at', 'Eignt', 'o')\n","('Eignt', 'o', 'Clock')\n","('o', 'Clock', 'on')\n","('Clock', 'on', 'thursday')\n","('on', 'thursday', ',')\n","('thursday', ',', 'hello')\n","(',', 'hello', 'how')\n","('hello', 'how', 'are')\n","('how', 'are', 'you')\n"]}]},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","sb = SnowballStemmer('english')\n","word = ['eight', 'clock', 'program', 'programs', 'programmer', 'programming' 'thursday', 'morning', ',', 'hello']\n","for w in word:\n","    print(w, \",\", sb.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hnmRWGsz_tId","executionInfo":{"status":"ok","timestamp":1717148565121,"user_tz":-240,"elapsed":6,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"f90b96fe-3675-4326-f34c-336d7174a84f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["eight , eight\n","clock , clock\n","program , program\n","programs , program\n","programmer , programm\n","programmingthursday , programmingthursday\n","morning , morn\n",", , ,\n","hello , hello\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","porter = PorterStemmer()\n","word = ['\"\"', 'eight', 'clock', 'program', 'programs', 'programmer', 'programming' 'thursday', 'morning', ',', 'hello']\n","print(\"Word, porter stem\")\n","for w in word:\n","    print(w, \",\", porter.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpQLWmEPB3y2","executionInfo":{"status":"ok","timestamp":1717148767121,"user_tz":-240,"elapsed":351,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"68aea630-8148-4c08-f6db-0aa2044d57a9"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Word, porter stem\n","\"\" , \"\"\n","eight , eight\n","clock , clock\n","program , program\n","programs , program\n","programmer , programm\n","programmingthursday , programmingthursday\n","morning , morn\n",", , ,\n","hello , hello\n"]}]},{"cell_type":"code","source":["nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","print('rocks',lem.lemmatize('rocks'))\n","print('thought',lem.lemmatize('thought'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNDndky3Ckjh","executionInfo":{"status":"ok","timestamp":1717149412885,"user_tz":-240,"elapsed":2292,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"923a635f-bd9c-4239-d4f3-45a741b323a2"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["rocks rock\n","thought thought\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","#lemmatize as nouns(default behaviour)\n","print('rocks as noun:', lem.lemmatize('rocks'))\n","print('thought as verb:', lem.lemmatize('thought'))\n","\n","#lematize as verbs\n","print('rocks as verb:', lem.lemmatize('rocks', pos='v'))\n","print('thought as verb:', lem.lemmatize('thought', pos='v'))\n","print('played as verb:', lem.lemmatize('played', pos='v'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e438cgSXFBFf","executionInfo":{"status":"ok","timestamp":1717149689040,"user_tz":-240,"elapsed":7,"user":{"displayName":"Farseena kayal vakkath","userId":"08373603390497225464"}},"outputId":"7fb94d3f-95be-4164-99fe-5bae28ffacef"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks as noun: rock\n","thought as verb: thought\n","rocks as verb: rock\n","thought as verb: think\n","played as verb: play\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9vp-I_nKF6mP"},"execution_count":null,"outputs":[]}]}